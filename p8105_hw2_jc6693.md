p8105_hw2_jc6693
================
Jingfeng Cao

## Problem 1

``` r
library(tidyverse)
library(readxl)
library(haven)
```

import data pols_month

``` r
pols_month_df = read_csv('fivethirtyeight_datasets/pols-month.csv') |>
  janitor::clean_names() |>
  separate(mon,into = c('year','month','day'),sep = '-') |>
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) |>
  mutate(month = lubridate::month(month,label = TRUE, abbr = FALSE)) |>
  mutate(president = case_when(prez_dem == 1 ~ 'dem', prez_gop == 1 ~ 'gop')) |>
  select(-prez_dem, -prez_gop, -day)
pols_month_df
```

    ## # A tibble: 822 × 9
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <ord>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 January        23      51     253      23      45     198 dem      
    ##  2  1947 February       23      51     253      23      45     198 dem      
    ##  3  1947 March          23      51     253      23      45     198 dem      
    ##  4  1947 April          23      51     253      23      45     198 dem      
    ##  5  1947 May            23      51     253      23      45     198 dem      
    ##  6  1947 June           23      51     253      23      45     198 dem      
    ##  7  1947 July           23      51     253      23      45     198 dem      
    ##  8  1947 August         23      51     253      23      45     198 dem      
    ##  9  1947 September      23      51     253      23      45     198 dem      
    ## 10  1947 October        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

import data snp

``` r
snp_df = read_csv('fivethirtyeight_datasets/snp.csv') |>
  janitor::clean_names() |>
  separate(date,into = c('month','day','year'),sep = '/') |>
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) |>
  mutate(year = case_when(year <= 25 ~ year+2000, year >= 26 ~ year+1900)) |>
  arrange(year,month) |>
  mutate(month = lubridate::month(month,label = TRUE, abbr = FALSE)) |>
  select(year,month, everything(), -day)
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month     close
    ##    <dbl> <ord>     <dbl>
    ##  1  1950 January    17.0
    ##  2  1950 February   17.2
    ##  3  1950 March      17.3
    ##  4  1950 April      18.0
    ##  5  1950 May        18.8
    ##  6  1950 June       17.7
    ##  7  1950 July       17.8
    ##  8  1950 August     18.4
    ##  9  1950 September  19.5
    ## 10  1950 October    19.5
    ## # ℹ 777 more rows

import data unemployment

``` r
unemployment_df = read_csv('fivethirtyeight_datasets/unemployment.csv') |>
  pivot_longer(Jan:Dec,names_to = 'month',values_to = 'unemployment') |>
  mutate(month = month.name[match(month, month.abb)]) |>
  janitor::clean_names() |>
  mutate(year = as.integer(year))
unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemployment
    ##    <int> <chr>            <dbl>
    ##  1  1948 January            3.4
    ##  2  1948 February           3.8
    ##  3  1948 March              4  
    ##  4  1948 April              3.9
    ##  5  1948 May                3.5
    ##  6  1948 June               3.6
    ##  7  1948 July               3.6
    ##  8  1948 August             3.9
    ##  9  1948 September          3.8
    ## 10  1948 October            3.7
    ## # ℹ 806 more rows

join and brief description

``` r
fivethirtyeight_df = left_join(pols_month_df,snp_df,by = c('year','month')) |>
  left_join(unemployment_df,by = c('year','month'))
fivethirtyeight_df
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 January      23      51     253      23      45     198 dem          NA
    ##  2  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  3  1947 March        23      51     253      23      45     198 dem          NA
    ##  4  1947 April        23      51     253      23      45     198 dem          NA
    ##  5  1947 May          23      51     253      23      45     198 dem          NA
    ##  6  1947 June         23      51     253      23      45     198 dem          NA
    ##  7  1947 July         23      51     253      23      45     198 dem          NA
    ##  8  1947 August       23      51     253      23      45     198 dem          NA
    ##  9  1947 Septem…      23      51     253      23      45     198 dem          NA
    ## 10  1947 October      23      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment <dbl>

the pols_month dataset contains 822 rows and 9 columns related to the
number of national politicians who are democratic or republican. snp
dataset contains contains 787 rows and 3 columns related to the closing
value of Standard & Poor’s stock market index (S&P). the umenployment
dataset contains 816 rows and 3 columns related to the percentage of
unemployment.  
After merging, the result dataset contains 822 rows and 11 columns. the
year ranges from 1947 to 2015, with some missing data of unemployment in
1947 and snp in 1947 to 1949. the key variables are year and month
showing time; govgop:president(total 7 variables) showing the
politicians; snp showing the stock’s values; unemployment showing the
unemployment rate.

## Problem 2

import clean the Mr. Trash Wheel sheet

``` r
mr_trash_wheel_df = read_excel('202509 Trash Wheel Collection Data.xlsx', sheet = 1, skip = 1) |>
  select(-...15,-...16) |>
  janitor::clean_names() |>
  head(-1) |>
  mutate(across(everything(), ~replace_na(.x, 0))) |>
  mutate(sports_balls = as.integer(round(sports_balls)))
mr_trash_wheel_df
```

    ## # A tibble: 707 × 14
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 697 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

import Professor Trash Wheel and Gwynnda data:

``` r
professor_df = read_excel('202509 Trash Wheel Collection Data.xlsx', sheet = 2, skip = 1) |>
  janitor::clean_names() |>
  head(-1) |>
  mutate(across(everything(), ~replace_na(.x, 0)))
professor_df
```

    ## # A tibble: 132 × 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 122 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
gwynnda_df = read_excel('202509 Trash Wheel Collection Data.xlsx', sheet = 4, skip = 1) |>
  janitor::clean_names() |>
  head(-1) |>
  mutate(across(everything(), ~replace_na(.x, 0)))
gwynnda_df
```

    ## # A tibble: 349 × 12
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 339 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

join them:

``` r
mr_trash_wheel_df = mutate(mr_trash_wheel_df, type = 'mr', year = as.integer(year))
professor_df = mutate(professor_df, type = 'professor', year = as.integer(year))
gwynnda_df = mutate(gwynnda_df, type = 'gwynnda', year = as.integer(year))
merge_df = bind_rows(mr_trash_wheel_df,professor_df,gwynnda_df) |>
  arrange(date) |>
  select(type,date,everything(),-dumpster)
merge_df
```

    ## # A tibble: 1,188 × 14
    ##    type  date                month  year weight_tons volume_cubic_yards
    ##    <chr> <dttm>              <chr> <int>       <dbl>              <dbl>
    ##  1 mr    2014-05-16 00:00:00 May    2014        4.31                 18
    ##  2 mr    2014-05-16 00:00:00 May    2014        2.74                 13
    ##  3 mr    2014-05-16 00:00:00 May    2014        3.45                 15
    ##  4 mr    2014-05-17 00:00:00 May    2014        3.1                  15
    ##  5 mr    2014-05-17 00:00:00 May    2014        4.06                 18
    ##  6 mr    2014-05-20 00:00:00 May    2014        2.71                 13
    ##  7 mr    2014-05-21 00:00:00 May    2014        1.91                  8
    ##  8 mr    2014-05-28 00:00:00 May    2014        3.7                  16
    ##  9 mr    2014-06-05 00:00:00 June   2014        2.52                 14
    ## 10 mr    2014-06-11 00:00:00 June   2014        3.76                 18
    ## # ℹ 1,178 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

in total, the dataset has 1188 rows of 14 variables, including type
showing the data comes from which wheel; date, month, year showing the
time of data collected; weight_tons showing the weight of garbage which
unit is ton; volume_cubic_yards showing the volume of garbage which unit
is cubic yard; from plastic_bottles to sports_balls(total 7 columns)
showing the amount of each type garbage; homes_powered showing the
amount of homes powered by the electricity generated from garbage.  
The total weight of trash collected by Professor Trash Wheel is 282.26
tons. The total number of cigarette butts collected by Gwynnda in June
of 2022 is 1.812^{4}.

## Problem 3

import data Zip Codes.csv

``` r
zipcodes_df = read_csv('zillow_data/Zip Codes.csv') |>
  janitor::clean_names() |>
  arrange(zip_code) |>
  select(zip_code,everything())
zipcodes_df
```

    ## # A tibble: 322 × 7
    ##    zip_code county   state_fips county_code county_fips file_date neighborhood  
    ##       <dbl> <chr>         <dbl> <chr>             <dbl> <chr>     <chr>         
    ##  1    10001 New York         36 061               36061 7/25/07   Chelsea and C…
    ##  2    10002 New York         36 061               36061 7/25/07   Lower East Si…
    ##  3    10003 New York         36 061               36061 7/25/07   Lower East Si…
    ##  4    10004 New York         36 061               36061 7/25/07   Lower Manhatt…
    ##  5    10005 New York         36 061               36061 7/25/07   Lower Manhatt…
    ##  6    10006 New York         36 061               36061 7/25/07   Lower Manhatt…
    ##  7    10007 New York         36 061               36061 7/25/07   Lower Manhatt…
    ##  8    10008 New York         36 061               36061 7/25/07   <NA>          
    ##  9    10009 New York         36 061               36061 7/25/07   Lower East Si…
    ## 10    10010 New York         36 061               36061 7/25/07   Gramercy Park…
    ## # ℹ 312 more rows

import data Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv

``` r
zori_df = read_csv('zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv') |>
  janitor::clean_names() |>
  pivot_wider(names_from = 'region_type', values_from = 'region_name') |>
  select(zip_code = zip,everything()) |>
  arrange(zip_code) |>
  pivot_longer(x2015_01_31:x2024_08_31,names_to = 'date', names_prefix = 'x', values_to = 'zori') |>
  drop_na() |>
  mutate(county = str_replace(county_name, " County$", "")) |>
  select(zip_code,county,date,zori,everything(),-state_name,-county_name)
zori_df
```

    ## # A tibble: 10,450 × 9
    ##    zip_code county   date        zori region_id size_rank state city     metro  
    ##       <dbl> <chr>    <chr>      <dbl>     <dbl>     <dbl> <chr> <chr>    <chr>  
    ##  1    10001 New York 2015_01_31 3855.     61615      4444 NY    New York New Yo…
    ##  2    10001 New York 2015_02_28 3892.     61615      4444 NY    New York New Yo…
    ##  3    10001 New York 2015_03_31 3898.     61615      4444 NY    New York New Yo…
    ##  4    10001 New York 2015_04_30 3970.     61615      4444 NY    New York New Yo…
    ##  5    10001 New York 2015_05_31 4033.     61615      4444 NY    New York New Yo…
    ##  6    10001 New York 2015_06_30 4071.     61615      4444 NY    New York New Yo…
    ##  7    10001 New York 2015_07_31 4067.     61615      4444 NY    New York New Yo…
    ##  8    10001 New York 2015_08_31 4070.     61615      4444 NY    New York New Yo…
    ##  9    10001 New York 2015_09_30 4040.     61615      4444 NY    New York New Yo…
    ## 10    10001 New York 2015_10_31 4023.     61615      4444 NY    New York New Yo…
    ## # ℹ 10,440 more rows

merge datasets

``` r
zillow_df = left_join(zori_df,zipcodes_df,by = c('zip_code','county')) |>
  arrange(zip_code,county,date)
zillow_df
```

    ## # A tibble: 10,450 × 14
    ##    zip_code county  date   zori region_id size_rank state city  metro state_fips
    ##       <dbl> <chr>   <chr> <dbl>     <dbl>     <dbl> <chr> <chr> <chr>      <dbl>
    ##  1    10001 New Yo… 2015… 3855.     61615      4444 NY    New … New …         36
    ##  2    10001 New Yo… 2015… 3892.     61615      4444 NY    New … New …         36
    ##  3    10001 New Yo… 2015… 3898.     61615      4444 NY    New … New …         36
    ##  4    10001 New Yo… 2015… 3970.     61615      4444 NY    New … New …         36
    ##  5    10001 New Yo… 2015… 4033.     61615      4444 NY    New … New …         36
    ##  6    10001 New Yo… 2015… 4071.     61615      4444 NY    New … New …         36
    ##  7    10001 New Yo… 2015… 4067.     61615      4444 NY    New … New …         36
    ##  8    10001 New Yo… 2015… 4070.     61615      4444 NY    New … New …         36
    ##  9    10001 New Yo… 2015… 4040.     61615      4444 NY    New … New …         36
    ## 10    10001 New Yo… 2015… 4023.     61615      4444 NY    New … New …         36
    ## # ℹ 10,440 more rows
    ## # ℹ 4 more variables: county_code <chr>, county_fips <dbl>, file_date <chr>,
    ## #   neighborhood <chr>

The final dataset is zillow_df, which has 10450 observations and 14
variables. It is arranged by first three columns which are
zip_code,county,date, noticed that there are few zip codes like 10463
and 11201 having multiple counties. The fourth variable is ZORI value
and each row represent an unique zip code in certain county in certain
time. So in total we have 10450 ZORI values in the data frame. There are
149 unique ZIP codes are included, and 43 unique neighborhoods.

``` r
zipcodes_zipcode = unique(zipcodes_df$zip_code)
zipcodes_zori = unique(zori_df$zip_code)
missing_zipcodes = setdiff(zipcodes_zipcode,zipcodes_zori)
missing_zipcodes
```

    ##   [1] 10008 10020 10041 10043 10045 10047 10048 10055 10072 10080 10081 10082
    ##  [13] 10087 10101 10102 10103 10104 10105 10106 10107 10108 10109 10110 10111
    ##  [25] 10112 10113 10114 10115 10116 10117 10118 10119 10120 10121 10122 10123
    ##  [37] 10124 10125 10126 10129 10130 10131 10132 10133 10138 10149 10150 10151
    ##  [49] 10152 10153 10154 10155 10156 10157 10158 10159 10160 10161 10163 10164
    ##  [61] 10165 10166 10167 10168 10169 10170 10171 10172 10173 10174 10175 10176
    ##  [73] 10177 10178 10179 10185 10197 10199 10213 10242 10249 10256 10259 10260
    ##  [85] 10261 10265 10268 10269 10270 10271 10272 10273 10274 10275 10276 10277
    ##  [97] 10278 10279 10281 10285 10286 10292 10302 10307 10309 10310 10311 10313
    ## [109] 10464 10474 10475 10499 10550 10704 10705 10803 11001 11004 11005 11040
    ## [121] 11096 11202 11224 11239 11241 11242 11243 11245 11247 11251 11252 11256
    ## [133] 11351 11352 11359 11362 11363 11371 11380 11381 11386 11405 11411 11412
    ## [145] 11413 11414 11416 11417 11419 11420 11421 11422 11423 11424 11425 11427
    ## [157] 11428 11429 11430 11431 11433 11436 11439 11451 11499 11559 11580 11690
    ## [169] 11694 11695 11697

There are 171 zip codes which appear in the ZIP code dataset but not in
the Zillow Rental Price dataset. Some zip codes might be excluded
because these place may not have home for rental. For example, 10041 is
Wall street which is a business area, and 11430 is JFK airport.

``` r
pandemic_df = filter(zillow_df, date == '2020_01_31' | date == '2021_01_31') |>
  pivot_wider(names_from = 'date', values_from = 'zori') |>
  janitor::clean_names() |>
  filter(!is.na(x2020_01_31)) |>
  mutate(price_drop = x2021_01_31 - x2020_01_31, percentage = -price_drop*100/x2020_01_31) |>
  select(price_drop,percentage,everything()) |>
  arrange(price_drop)
pandemic_df
```

    ## # A tibble: 82 × 16
    ##    price_drop percentage zip_code county   region_id size_rank state city  metro
    ##         <dbl>      <dbl>    <dbl> <chr>        <dbl>     <dbl> <chr> <chr> <chr>
    ##  1      -913.       14.4    10007 New York     61621     10357 NY    New … New …
    ##  2      -748.       16.2    10069 New York     61664     10691 NY    New … New …
    ##  3      -714.       21.0    10009 New York     61623       531 NY    New … New …
    ##  4      -712.       19.1    10016 New York     61630       872 NY    New … New …
    ##  5      -710.       17.3    10001 New York     61615      4444 NY    New … New …
    ##  6      -710.       19.5    10002 New York     61616       139 NY    New … New …
    ##  7      -706.       22.4    10004 New York     61618     30490 NY    New … New …
    ##  8      -698.       19.5    10038 New York     61652      5069 NY    New … New …
    ##  9      -686.       18.9    10012 New York     61626      5253 NY    New … New …
    ## 10      -685.       18.5    10010 New York     61624      2896 NY    New … New …
    ## # ℹ 72 more rows
    ## # ℹ 7 more variables: state_fips <dbl>, county_code <chr>, county_fips <dbl>,
    ## #   file_date <chr>, neighborhood <chr>, x2020_01_31 <dbl>, x2021_01_31 <dbl>

``` r
library(knitr)

table_temp = head(pandemic_df,n = 10) |>
  select(1:5) |>
  kable()
table_temp
```

| price_drop | percentage | zip_code | county   | region_id |
|-----------:|-----------:|---------:|:---------|----------:|
|  -912.5966 |   14.40742 |    10007 | New York |     61621 |
|  -748.1245 |   16.18251 |    10069 | New York |     61664 |
|  -714.2550 |   20.96778 |    10009 | New York |     61623 |
|  -711.7045 |   19.07474 |    10016 | New York |     61630 |
|  -710.4499 |   17.29389 |    10001 | New York |     61615 |
|  -710.3028 |   19.48482 |    10002 | New York |     61616 |
|  -705.9608 |   22.41389 |    10004 | New York |     61618 |
|  -697.5853 |   19.52270 |    10038 | New York |     61652 |
|  -686.2218 |   18.91165 |    10012 | New York |     61626 |
|  -684.9304 |   18.52523 |    10010 | New York |     61624 |

I think it’s true that rental prices fluctuated dramatically during the
COVID-19 pandemic. The drop in these zip codes are more than 600 and the
drop percentages are more than 14%. Besides, these are all come from New
York County.
