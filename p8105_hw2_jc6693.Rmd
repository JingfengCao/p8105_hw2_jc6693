---
title: 'p8105_hw2_jc6693'
author: 'Jingfeng Cao'
output: github_document
---

## Problem 1

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

import data pols_month
```{r message=FALSE, warning=FALSE}
pols_month_df = read_csv('fivethirtyeight_datasets/pols-month.csv') |>
  janitor::clean_names() |>
  separate(mon,into = c('year','month','day'),sep = '-') |>
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) |>
  mutate(month = lubridate::month(month,label = TRUE, abbr = FALSE)) |>
  mutate(president = case_when(prez_dem == 1 ~ 'dem', prez_gop == 1 ~ 'gop')) |>
  select(-prez_dem, -prez_gop, -day)
pols_month_df
```

import data snp
```{r message=FALSE, warning=FALSE}
snp_df = read_csv('fivethirtyeight_datasets/snp.csv') |>
  janitor::clean_names() |>
  separate(date,into = c('month','day','year'),sep = '/') |>
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) |>
  mutate(year = case_when(year <= 25 ~ year+2000, year >= 26 ~ year+1900)) |>
  arrange(year,month) |>
  mutate(month = lubridate::month(month,label = TRUE, abbr = FALSE)) |>
  select(year,month, everything(), -day)
snp_df
```

import data unemployment
```{r message=FALSE, warning=FALSE}
unemployment_df = read_csv('fivethirtyeight_datasets/unemployment.csv') |>
  pivot_longer(Jan:Dec,names_to = 'month',values_to = 'unemployment') |>
  mutate(month = month.name[match(month, month.abb)]) |>
  janitor::clean_names() |>
  mutate(year = as.integer(year))
unemployment_df
```

join and brief description

```{r}
fivethirtyeight_df = left_join(pols_month_df,snp_df,by = c('year','month')) |>
  left_join(unemployment_df,by = c('year','month'))
fivethirtyeight_df
```

the pols_month dataset contains 822 rows and 9 columns related to the number of national politicians who are democratic or republican. snp dataset contains contains 787 rows and 3 columns related to the closing value of Standard & Poorâ€™s stock market index (S&P). the umenployment dataset contains 816 rows and 3 columns related to the percentage of unemployment.   
After merging, the result dataset contains 822 rows and 11 columns. the year ranges from 1947 to 2015, with some missing data of unemployment in 1947 and snp in 1947 to 1949. the key variables are year and month showing time; govgop:president(total 7 variables) showing the politicians; snp showing the stock's values; unemployment showing the unemployment rate.

## Problem 2

import clean the Mr. Trash Wheel sheet
```{r message=FALSE, warning=FALSE}
mr_trash_wheel_df = read_excel('202509 Trash Wheel Collection Data.xlsx', sheet = 1, skip = 1) |>
  select(-...15,-...16) |>
  janitor::clean_names() |>
  head(-1) |>
  mutate(across(everything(), ~replace_na(.x, 0))) |>
  mutate(sports_balls = as.integer(round(sports_balls)))
mr_trash_wheel_df
```

import Professor Trash Wheel and Gwynnda data:
```{r message=FALSE, warning=FALSE}
professor_df = read_excel('202509 Trash Wheel Collection Data.xlsx', sheet = 2, skip = 1) |>
  janitor::clean_names() |>
  head(-1) |>
  mutate(across(everything(), ~replace_na(.x, 0)))
professor_df
gwynnda_df = read_excel('202509 Trash Wheel Collection Data.xlsx', sheet = 4, skip = 1) |>
  janitor::clean_names() |>
  head(-1) |>
  mutate(across(everything(), ~replace_na(.x, 0)))
gwynnda_df
```

join them:
```{r}
mr_trash_wheel_df = mutate(mr_trash_wheel_df, type = 'mr', year = as.integer(year))
professor_df = mutate(professor_df, type = 'professor', year = as.integer(year))
gwynnda_df = mutate(gwynnda_df, type = 'gwynnda', year = as.integer(year))
merge_df = bind_rows(mr_trash_wheel_df,professor_df,gwynnda_df) |>
  arrange(date) |>
  select(type,date,everything(),-dumpster)
merge_df
```

in total, the dataset has 1188 rows of 14 variables, including type showing the data comes from which wheel; date, month, year showing the time of data collected; weight_tons showing the weight of garbage which unit is ton; volume_cubic_yards showing the volume of garbage which unit is cubic yard; from plastic_bottles to sports_balls(total 7 columns) showing the amount of each type garbage; homes_powered showing the amount of homes powered by the electricity generated from garbage.     
The total weight of trash collected by Professor Trash Wheel is `r sum(professor_df$weight_tons)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is `r sum(filter(gwynnda_df,month == 'June',year == 2022)$cigarette_butts)`. 

## Problem 3

import data Zip Codes.csv
```{r message=FALSE, warning=FALSE}
zipcodes_df = read_csv('zillow_data/Zip Codes.csv') |>
  janitor::clean_names() |>
  arrange(zip_code) |>
  select(zip_code,everything())
zipcodes_df
```

import data Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv
```{r message=FALSE, warning=FALSE}
zori_df = read_csv('zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv') |>
  janitor::clean_names() |>
  pivot_wider(names_from = 'region_type', values_from = 'region_name') |>
  select(zip_code = zip,everything()) |>
  arrange(zip_code) |>
  pivot_longer(x2015_01_31:x2024_08_31,names_to = 'date', names_prefix = 'x', values_to = 'zori') |>
  drop_na() |>
  mutate(county = str_replace(county_name, " County$", "")) |>
  select(zip_code,county,date,zori,everything(),-state_name,-county_name)
zori_df
```

merge datasets
```{r}
zillow_df = left_join(zori_df,zipcodes_df,by = c('zip_code','county')) |>
  arrange(zip_code,county,date)
zillow_df
```

The final dataset is zillow_df, which has 10450 observations and 14 variables. It is arranged by first three columns which are zip_code,county,date, noticed that there are few zip codes like 10463 and 11201 having multiple counties. The fourth variable is ZORI value and each row represent an unique zip code in certain county in certain time. So in total we have 10450 ZORI values in the data frame. There are `r length(unique(zillow_df$zip_code))` unique ZIP codes are included, and `r length(unique(zillow_df$neighborhood))` unique neighborhoods.  

```{r}
zipcodes_zipcode = unique(zipcodes_df$zip_code)
zipcodes_zori = unique(zori_df$zip_code)
missing_zipcodes = setdiff(zipcodes_zipcode,zipcodes_zori)
missing_zipcodes
```
There are `r length(missing_zipcodes)` zip codes which appear in the ZIP code dataset but not in the Zillow Rental Price dataset.
Some zip codes might be excluded because these place may not have home for rental. For example, 10041 is Wall street which is a business area, and 11430 is JFK airport. 

```{r}
pandemic_df = filter(zillow_df, date == '2020_01_31' | date == '2021_01_31') |>
  pivot_wider(names_from = 'date', values_from = 'zori') |>
  janitor::clean_names() |>
  filter(!is.na(x2020_01_31)) |>
  mutate(price_drop = x2021_01_31 - x2020_01_31, percentage = -price_drop*100/x2020_01_31) |>
  select(price_drop,percentage,everything()) |>
  arrange(price_drop)
pandemic_df
```

```{r}
library(knitr)

table_temp = head(pandemic_df,n = 10) |>
  select(1:5) |>
  kable()
table_temp
```

I think it's true that rental prices fluctuated dramatically during the COVID-19 pandemic. The drop in these zip codes are more than 600 and the drop percentages are more than 14%. Besides, these are all come from New York County. 
